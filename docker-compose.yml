version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: youtube-ai-postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - youtube-ai-network

  # Redis Message Broker
  redis:
    image: redis:7-alpine
    container_name: youtube-ai-redis
    volumes:
      - ./data/redis:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - youtube-ai-network

  # FastAPI Backend Server
  backend:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: youtube-ai-backend
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - SECRET_KEY=${SECRET_KEY}
      - ENVIRONMENT=${ENVIRONMENT}
      - LLM_PROVIDER=${LLM_PROVIDER}
      - WHISPER_MODEL_SIZE=${WHISPER_MODEL_SIZE}
      - FRONTEND_URL=${FRONTEND_URL}
    volumes:
      - ./server/app:/app/app
      - ./server/temp:/app/temp
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
    networks:
      - youtube-ai-network

  # Celery Worker
  worker:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: youtube-ai-worker
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - SECRET_KEY=${SECRET_KEY}
      - ENVIRONMENT=${ENVIRONMENT}
      - LLM_PROVIDER=${LLM_PROVIDER}
      - WHISPER_MODEL_SIZE=${WHISPER_MODEL_SIZE}
    volumes:
      - ./server/app:/app/app
      - ./server/temp:/app/temp
      - ./data/models:/app/models
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: celery -A app.celery_app worker --loglevel=info
    networks:
      - youtube-ai-network

  # React Frontend
  frontend:
    build:
      context: ./client
      dockerfile: Dockerfile
    container_name: youtube-ai-frontend
    environment:
      - REACT_APP_API_URL=http://localhost:8000
    ports:
      - "3000:80"
    depends_on:
      - backend
    networks:
      - youtube-ai-network

networks:
  youtube-ai-network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
